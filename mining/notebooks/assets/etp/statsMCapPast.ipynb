{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149b7738",
   "metadata": {},
   "source": [
    "# Read n Clean MCap with pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115dba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    WARNING CONTROL to display or ignore all warnings\n",
    "'''\n",
    "import warnings; warnings.simplefilter('ignore')     #switch betweeb 'default' and 'ignore'\n",
    "import traceback\n",
    "\n",
    "''' Set debug flag to view extended error messages; else set it to False to turn off debugging mode '''\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46d5864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functional APP-libraries in REZAWARE-package of REZAWARE-module imported successfully!\n",
      "All functional LOGRETURNS-libraries in ETP-package of ASSETS-module imported successfully!\n",
      "All functional SPARKDBWLS-libraries in LOAD-package of ETL-module imported successfully!\n",
      "All functional SPARKCLEANNRICH-libraries in TRANSFORM-package of ETL-module imported successfully!\n",
      "All packages in utils ml timeseries RollingStats imported successfully!\n",
      "logReturns Class initialization complete\n",
      "\n",
      "Class initialization and load complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "sys.path.insert(1,\"/home/nuwan/workspace/rezaware/\")\n",
    "import rezaware as reza\n",
    "from utils.modules.etl.load import sparkDBwls as sdb\n",
    "from utils.modules.etl.transform import sparkCleanNRich as scne\n",
    "from mining.modules.assets.etp import logReturns as log\n",
    "from utils.modules.ml.timeseries import rollingstats as stats\n",
    "\n",
    "''' restart initiate classes '''\n",
    "if debug:\n",
    "    import importlib\n",
    "    reza = importlib.reload(reza)\n",
    "    log = importlib.reload(log)\n",
    "    sdb = importlib.reload(sdb)\n",
    "    scne = importlib.reload(scne)\n",
    "    stats= importlib.reload(stats)\n",
    "    \n",
    "__desc__ = \"analyze crypto market capitalization time series data\"\n",
    "# clsSDB = sdb.SQLWorkLoads(desc=__desc__)\n",
    "clsSCNR=scne.Transformer(desc=__desc__)\n",
    "clsROR =log.RatioOfReturns(desc=__desc__)\n",
    "clsStat=stats.RollingStats(desc=__desc__)\n",
    "''' optional - if not specified class will use the default values '''\n",
    "# prop_kwargs = {\"WRITE_TO_TMP\":True,   # necessary to emulate the etl dag\n",
    "#               }\n",
    "print(\"\\nClass initialization and load complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0dd26e",
   "metadata": {},
   "source": [
    "## Read data from mcap_past\n",
    "We apply a query to select assets with mcap > 1.0 million. Any missing values are imputed with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c04b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait a moment, retrieving data ...\n",
      "23/01/20 07:26:55 WARN Utils: Your hostname, FarmRaiderTester resolves to a loopback address: 127.0.1.1; using 192.168.124.15 instead (on interface enp2s0)\n",
      "23/01/20 07:26:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/01/20 07:26:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/01/20 07:26:56 WARN FileSystem: Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem Unable to get public no-arg constructor\n",
      "23/01/20 07:26:56 WARN FileSystem: java.lang.NoClassDefFoundError: com/google/api/client/auth/oauth2/Credential\n",
      "23/01/20 07:26:56 WARN FileSystem: java.lang.ClassNotFoundException: com.google.api.client.auth.oauth2.Credential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 07:30:01 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 07:30:21 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 07:30:45 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 07:35:16 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 07:37:02 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 07:39:15 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3320 rows and 3 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_from_date = '2022-01-01'\n",
    "_to_date = '2022-01-02'\n",
    "# _query = \"select * from warehouse.mcap_past \"+\\\n",
    "#         f\"where mcap_date >= '{_from_date}' and \"+\\\n",
    "#         f\"mcap_date <= '{_to_date}'\"\n",
    "_query = \"select * from warehouse.mcap_past \"+\\\n",
    "        f\"where mcap_date between '{_from_date}' and '{_to_date}' \"+\\\n",
    "        f\"and mcap_value > 1000000\"\n",
    "_kwargs = {\n",
    "    \"TABLENAME\":'warehouse.mcap_past',\n",
    "    \"COLUMN\":'mcap_date',\n",
    "    \"FROMDATETIME\":_from_date,\n",
    "    \"TODATETIME\":_to_date,\n",
    "    \"PARTITIONS\":2,\n",
    "    \"AGGREGATE\":'avg',\n",
    "    \"PIVCOLUMNS\":['cofix','paypolitan-token','raven-protocol',\n",
    "               'nft-index','beldex','mt-pelerin-shares']\n",
    "}\n",
    "\n",
    "# print(clsSpark.dbSchema)\n",
    "mcap_sdf = clsROR.read_n_clean_mcap(query=_query,**_kwargs)\n",
    "# mcap_sdf = clsROR.read_n_clean_mcap(**_kwargs)\n",
    "\n",
    "print(\"Loaded %d rows and %d columns\" % (mcap_sdf.count(),len(mcap_sdf.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53a90a",
   "metadata": {},
   "source": [
    "## Compute LogROR for all assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d7e14d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 15:20:33 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 15:20:44 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 87:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 15:20:50 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 96:>                                                         (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 15:20:55 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| mcap_date|          asset_name|          mcap_value| mcap_value_prev_val|           mcap_diff|             log_ror|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|2022-01-02|            switcheo|25959201.75722492...|11336695.15087185...|14622506.60635306...|-0.35980487434341657|\n",
      "|2022-01-02|           primecoin|4869520.968668153...|2382648.070384798...|2486872.898283354...| -0.3104265594101802|\n",
      "|2022-01-02|           cypherium|11824476.85075602...|6272519.311846281...|5551957.538909744...| -0.2753399906925486|\n",
      "|2022-01-02|           micropets|38036463.67628028...|23995041.05886446...|14041422.61741581...|-0.20007871162365293|\n",
      "|2022-01-02|               eqifi|35476164.52149334...|23447442.77929092...|12028721.74220241...|-0.17984124933339615|\n",
      "|2022-01-02|        civilization|36663264.25913747...|24457919.83136880...|12205344.42776866...|-0.17581166342946708|\n",
      "|2022-01-02|    sunny_aggregator|1738669.264608675...|1172086.646818428...|566582.6177902467...|-0.17125698977402223|\n",
      "|2022-01-02|      sentinel_group|9355572.169118403...|6774144.753243244...|2581427.415875159...| -0.1402158472719597|\n",
      "|2022-01-02|                dovu|4452192.764274383...|3265745.277575480...|1186447.486698902...|-0.13459159270723833|\n",
      "|2022-01-02|                blox|47813170.93521399...|35407033.36141334...|12406137.57380065...| -0.1304579293191895|\n",
      "|2022-01-02|              banana|2652244.146502461...|1976467.008082092...|675777.1384203688...|-0.12772365705491295|\n",
      "|2022-01-02|         snowblossom|17269935.38509905...|12890943.47429722...|4378991.910801828...|-0.12700625944077765|\n",
      "|2022-01-02|    nix_bridge_token|13843097.95274681...|10362646.08764819...|3480451.865098620...|-0.12576236037955008|\n",
      "|2022-01-02|     privapp_network|1598676.756776322...|1198682.860172238...|399993.8966040844...|-0.12505630155924294|\n",
      "|2022-01-02|              apenft|123237222.1994060...|93653417.61062110...|29583804.58878491...|-0.11921840954427274|\n",
      "|2022-01-02|            keep3rv1|388618836.2489745...|296017547.8696393...|92601288.37933520...|-0.11820635171421048|\n",
      "|2022-01-02|              onooks|8344348.402767301...|6375653.863351535...|1968694.539415766...|-0.11686742026443878|\n",
      "|2022-01-02|            lunachow|1497234.810752391...|1152614.381833936...|344620.4289184553...| -0.1136057327546136|\n",
      "|2022-01-02|             vidulum|2232679.523892047...|1722942.026329542...|509737.4975625050...|-0.11255600198389906|\n",
      "|2022-01-02|media_licensing_t...|32504306.97502931...|25130175.48944309...|7374131.485586219...|-0.11174522740502646|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs={\n",
    "    \"PREVALCOLNAME\":'mcap_prev_val',\n",
    "    \"DIFFCOLNAME\":'mcap_diff',\n",
    "    \"LOGCOLNAME\":'log_ror'\n",
    "}\n",
    "_mcap_log_ror, _log_col = clsROR.get_log_ror(\n",
    "    data=mcap_sdf,\n",
    "    num_col_name=\"mcap_value\",\n",
    "    part_column ='asset_name',\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "_mcap_log_ror.filter(_mcap_log_ror.log_ror.isNotNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f6f24",
   "metadata": {},
   "source": [
    "## Weighted Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb7ae1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 375:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 21:14:44 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 21:14:48 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 381:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 21:14:53 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 385:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 21:14:55 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1660"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_wr_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a39609d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 280:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:52:01 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:52:05 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 286:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:52:10 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 298:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:53:26 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:53:30 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 304:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:53:36 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 308:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:53:37 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 322:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:54:52 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:54:55 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 328:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:55:00 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 332:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:55:02 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:55:03 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/01/20 20:55:05 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 351:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:56:19 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:56:23 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 357:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:56:27 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 361:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:56:29 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 929, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 668, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 373, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/nuwan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_10754/2412683241.py\", line 1, in <cell line: 1>\n",
      "    _wr_dates, _wr_data=clsROR.update_weighted_portfolio(\n",
      "  File \"/home/nuwan/workspace/rezaware/mining/modules/assets/etp/logReturns.py\", line 563, in update_weighted_portfolio\n",
      "    logger.debug(\"Proceeding with data for with % dates\",str(_valid_date_list))\n",
      "Message: 'Proceeding with data for with % dates'\n",
      "Arguments: ('[datetime.date(2022, 1, 2)]',)\n"
     ]
    }
   ],
   "source": [
    "_wr_dates, _wr_data=clsROR.update_weighted_portfolio(\n",
    "    data=_mcap_log_ror,\n",
    "    date_col='mcap_date',\n",
    "    val_col='log_ror',\n",
    "    topN=23,\n",
    "    size=100,\n",
    "    **kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b582b",
   "metadata": {},
   "source": [
    "## SMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb7109da",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs={\n",
    "    \"DATETIMEATTR\":'mcap_date',\n",
    "    \"WINLENGTH\":7,\n",
    "    \"WINUNIT\":'DAY',\n",
    "}\n",
    "_sma_sdf=clsStat.simple_moving_stats(\n",
    "    column='diff',   # column name to apply the rolling computation\n",
    "    stat_op=\"mean\", # stat operation sum, mean or standard deviation\n",
    "    data=_mcap_log_ror,   # data set\n",
    "    **kwargs,    # \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b0e50f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/18 16:08:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/18 16:08:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/18 16:08:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 289:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/18 16:09:19 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/18 16:09:19 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 291:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/18 16:09:21 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/18 16:09:21 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/18 16:09:22 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 294:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/18 16:09:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/18 16:09:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/18 16:09:29 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 298:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/18 16:09:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/18 16:09:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/18 16:09:32 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 303:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+--------------------+------------------+--------------------+--------------------+\n",
      "|          mcap_date|        asset_name|          mcap_value|         mcap_diff|                diff|   rolling_mean_diff|\n",
      "+-------------------+------------------+--------------------+------------------+--------------------+--------------------+\n",
      "|2022-01-01 00:00:00|            0chain|18581739.78078547...| 7.290301186807742|-930233.240037870...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|              1_up|6580366.707037671...|   6.8616358287375|-691331.205561129...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|              1art|20450189.55773175...| 7.363364636916094|-2636658.08537944...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|             1inch|1025227565.328557...| 8.979442079049766|71461032.82505580...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|            1world|2254182.045747336...| 6.312876221139709|198877.3184413719...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|              2key|1106885.446348409...| 6.044102677253574|               0E-20|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|           42_coin|3832104.567015460...|6.5441736578130625|331253.3195671700...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|             88mph|10824218.47269857...| 7.093835175095548|-1587593.13668197...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|              8pay|3610012.139665701...| 6.605679991693943|-423468.639156704...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|              aave|3476942672.293371...| 9.464220656447015|564746300.6006827...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|        aavegotchi|156473485.9974581...| 8.143642900396662|17272311.24812794...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|        abcc_token|2046882.170612630...| 6.296353324263376|68303.49426347810...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|ac_milan_fan_token|10194427.84189629...| 6.985947949187111|512809.7045598960...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|             acent|7743380.066421100...| 6.707254863284722|2647081.498949518...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|          acryptos|13564545.38850261...| 7.053549835466283|2252273.481894585...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|         acryptosi|4076581.141450484...|  6.53056094902732|683760.1298536055...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|            adaboy|1780421.066847682...| 6.058849793278639|635304.2483060820...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|      adamant_coin|1444722.780595567...| 6.455594505421806|-1410200.91634160...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00| adamant_messenger|2307406.573969466...| 6.268898664519726|450035.5564469726...|66178035.76083997...|\n",
      "|2022-01-01 00:00:00|              adax|40643051.97006576...|7.4184522237585275|14433944.97632884...|66178035.76083997...|\n",
      "+-------------------+------------------+--------------------+------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_sma_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb99563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
